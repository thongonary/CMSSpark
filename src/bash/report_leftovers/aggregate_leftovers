#!/bin/sh

if [ $# -eq 0 ] || [ "$1" == "-h" ] || [ "$1" == "-help" ] || [ "$1" == "--help" ]; then
    echo "Usage: ./"$(basename "$0")" <date> [location] [inst]"
    echo "Example: ./"$(basename "$0")" 20170228 /cms/users/$USER/leftovers all"
    echo "<date> = PhEDEx date in the following format: YYYYMMDD."
    echo "[location] = hdfs location of resulting files. Default: /cms/users/$USER/leftovers"
    echo "[inst] = DBS instance. Possible values: global, phys01, phys02, phys03, all. Default: all"
    exit 0
fi

# Parse date argument
date=''

if [[ -n $1 ]]
then
    date=$1
fi

date_length=${#date}
if [[ $date_length != 8 ]]
then
    echo 'Invalid date. Correct format: YYYYMMDD. Example: 20170228'
    exit
fi

echo 'Aggregating for date: '$date

hdir=/cms/users/$USER/leftovers

if [[ -n $2 ]]
then
    hdir=$2
fi

if [[ $hdir != hdfs://* ]]
then
    hdir=hdfs://$hdir
fi

echo 'Results path: '$hdir

inst='all'
if [[ -n $3 ]]
then
    inst=$3
fi

echo 'DBS instances: '$inst

# Get current script's absolute path
scriptpath="$( cd "$(dirname "$0")" ; pwd -P )"

# Remove previous data first
hadoop fs -rm -r -skipTrash $hdir

PYTHONPATH=$scriptpath/../../python $scriptpath/../../../bin/run_spark /reports/aggregate_leftovers.py --fout=$hdir --yarn --verbose --date=$date --inst=$inst

hadoop fs -test -e $hdir
exists=$?

# Download results and recreate csv files only if results exist in hdfs
if [[ $exists -eq 0 ]]
then
    result_dir="$(basename $hdir)"

    # Delete previously downloaded directory and download new one
    rm -rf "$scriptpath/$result_dir"
    hadoop fs -get $hdir $scriptpath

    # Extract all leftovers header
    head -1 $scriptpath/$result_dir/all/part-00000 > $scriptpath/leftovers_all_df.csv

    # Concatenate all parts except header
    header=`cat $scriptpath/leftovers_all_df.csv`
    cat $scriptpath/$result_dir/all/part* | grep -v $header >> $scriptpath/leftovers_all_df.csv

    # Extract orphan leftovers header
    head -1 $scriptpath/$result_dir/orphans/part-00000 > $scriptpath/leftovers_orphans_df.csv

    # Concatenate all parts except header
    header=`cat $scriptpath/leftovers_orphans_df.csv`
    cat $scriptpath/$result_dir/orphans/part* | grep -v $header >> $scriptpath/leftovers_orphans_df.csv

    # Uncomment following lines if you want to copy results to cernbox directory
    #cp $scriptpath/leftovers_all_df.csv /eos/user/a/$USER/leftovers/leftovers_all_df.csv
    #cp $scriptpath/leftovers_orphans_df.csv /eos/user/a/$USER/leftovers/leftovers_orphans_df.csv
    #(cd /eos/user/a/$USER/leftovers/; echo 'Dataframe availible here:' $(pwd)/'leftovers_all_df.csv')
    #(cd /eos/user/a/$USER/leftovers/; echo 'Dataframe availible here:' $(pwd)/'leftovers_orphans_df.csv')
fi
